{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes Information Criterion\n",
    "- The bayes information criterion is a method of model selection that can be used when we don't have a holdout/validation dataset\n",
    "- It is given by $$BIC = \\log(n)k - 2 \\log (\\hat{L})$$ where $n$ is the number of training examples, $k$ is the number of parameters in the model (basically correlated w/model complexity), and $\\hat{L}$ is the maximized value of the likelihood function (i.e. the probability of observing the dataset, which was maximized in the learning process by setting the parameters $\\theta$ to maximize the likelihood function). \n",
    "- Generally, we want to select models with low BIC. This is because a small first term means that the model is relatively less complex, and a large likelihood means that we fit the data well. If we had a high BIC, it means that either our model was overly complex and the likelihood does  not justify it's complexity, or the model was not especially complex, but the likelihood was very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
