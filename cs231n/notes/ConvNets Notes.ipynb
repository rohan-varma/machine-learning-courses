{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolutional Layers\n",
    "\n",
    "- Given an input image represented as a square matrix with dimension $n$, the result of running a convolutional layer operation with a filter of size $f$ and stride length $l$ results in an output size of $(n-f)/l + 1$. \n",
    "- For example, if we have a 7 x 7 input image and a filter of size 3 x 3 and a stride of 2, then our output would have size 3 x 3. If we don't get a whole number for this then we can't really use that stride/filter combo, since it doesn't line up properly with our image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- We can also zero-pad the borders to preserve the spatial input size\n",
    "- Doing this zero-padding can be useful because it allows us to add several more convolutional layers than if we did not zero-pad (because after several conv layers with no zero-padding the spatial size will become too small for a conv op to be meaningful). \n",
    "- This also allows us to keep information around the edges of the image instead of simply discarding it, leading to a potential increase in perf\n",
    "- Easier to implement because you don't have to worry about how height and width changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Example\n",
    "- Input of 32 x 32 x 3, apply 6 filters each of 5 x 5 x 3 to get an output of 28 * 28 * 6 (the 6 is the number of feature maps/filters we applied). \n",
    "- Then in the next layer, apply 10 filters each of 5 * 5 * 6 to get an output of 24 * 24 * 10 (10 is again the number of filters we applied). \n",
    "- Conv layer consists of the convolution step followed by a relu and then possibly a pooling layer such as max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Deconv Layers\n",
    "- Kind of like the inverse of convolution operations - imagine taking the result of a convolution operation with a kernel and that kernel, and restoring the original image\n",
    "- This process is more similar to a transposed convolution/fractionally strided convolution\n",
    "- It increases the spatial field of an image as oppposed to decreasing it\n",
    "- Goes hand-in-hand with the gradient: If a convolution is in the forward pass then the gradient there basically computes a transposed convolution, if a transposed convolution exists in the forward pass then the gradient is the respective convolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
